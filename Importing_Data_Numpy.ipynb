{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1efe1295",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e3171b",
   "metadata": {},
   "source": [
    "## np.loadtxt() vs np.genfromtxt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe2f0328",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2000.,    40.,   365.,  3121.,  4241., 13621.],\n",
       "       [ 2000.,    40.,   365.,  3061.,  4171., 15041.],\n",
       "       [ 1000.,    40.,   365.,  2160.,  3280., 15340.],\n",
       "       ...,\n",
       "       [ 2000.,    40.,   365.,  4201.,  5001., 16600.],\n",
       "       [ 1000.,    40.,   365.,  2080.,  3320., 15600.],\n",
       "       [ 2000.,    40.,   365.,  4601.,  4601., 16600.]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = \"C:/Users/m.pirela.escobar/OneDrive - Accenture/Documents/Courses/Data_Analyst/Data Analyst Course/S10 - Working with Text Files/L15/Lending-Company-Numeric-Data.csv\"\n",
    "leading_co_data_numeric_1 = np.loadtxt(filename, delimiter = ',')\n",
    "leading_co_data_numeric_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a93550fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ahora usando genfromtxt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71db263d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2000.,    40.,   365.,  3121.,  4241., 13621.],\n",
       "       [ 2000.,    40.,   365.,  3061.,  4171., 15041.],\n",
       "       [ 1000.,    40.,   365.,  2160.,  3280., 15340.],\n",
       "       ...,\n",
       "       [ 2000.,    40.,   365.,  4201.,  5001., 16600.],\n",
       "       [ 1000.,    40.,   365.,  2080.,  3320., 15600.],\n",
       "       [ 2000.,    40.,   365.,  4601.,  4601., 16600.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = \"C:/Users/m.pirela.escobar/OneDrive - Accenture/Documents/Courses/Data_Analyst/Data Analyst Course/S10 - Working with Text Files/L15/Lending-Company-Numeric-Data.csv\"\n",
    "leading_co_data_numeric_2 = np.genfromtxt(filename, delimiter = ',')\n",
    "leading_co_data_numeric_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ce6c3f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Para saber si son iguales los arrays generados\n",
    "np.array_equal(leading_co_data_numeric_1, leading_co_data_numeric_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb68be9f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: ''",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-9d42bae9c634>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mfilename\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"C:/Users/m.pirela.escobar/OneDrive - Accenture/Documents/Courses/Data_Analyst/Data Analyst Course/S10 - Working with Text Files/L15/Lending-Company-Numeric-Data-NAN.csv\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mleading_co_data_numeric_NAN\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloadtxt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdelimiter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m';'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mleading_co_data_numeric_NAN\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\numpy\\lib\\npyio.py\u001b[0m in \u001b[0;36mloadtxt\u001b[1;34m(fname, dtype, comments, delimiter, converters, skiprows, usecols, unpack, ndmin, encoding, max_rows, like)\u001b[0m\n\u001b[0;32m   1161\u001b[0m                 \u001b[1;31m# Convert each value according to its column, then pack it\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1162\u001b[0m                 \u001b[1;31m# according to the dtype's nesting, and store it.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1163\u001b[1;33m                 \u001b[0mchunk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpacker\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconvert_row\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1164\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mchunk\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# The islice is empty, i.e. we're done.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1165\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\numpy\\lib\\npyio.py\u001b[0m in \u001b[0;36mconvert_row\u001b[1;34m(vals, _conv)\u001b[0m\n\u001b[0;32m   1140\u001b[0m             \u001b[1;31m# equal dtypes.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1141\u001b[0m             \u001b[1;32mdef\u001b[0m \u001b[0mconvert_row\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_conv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconverters\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1142\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_conv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1143\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1144\u001b[0m             \u001b[1;32mdef\u001b[0m \u001b[0mconvert_row\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\numpy\\lib\\npyio.py\u001b[0m in \u001b[0;36m_floatconv\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    723\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_floatconv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    724\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 725\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# The fastest path.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    726\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    727\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;34m'0x'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Don't accidentally convert \"a\" (\"0xa\") to 10.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: ''"
     ]
    }
   ],
   "source": [
    "# Sabiendo que el m√©todo genfromtxt es mejor para manejar valores nulos\n",
    "\n",
    "filename = \"C:/Users/m.pirela.escobar/OneDrive - Accenture/Documents/Courses/Data_Analyst/Data Analyst Course/S10 - Working with Text Files/L15/Lending-Company-Numeric-Data-NAN.csv\"\n",
    "leading_co_data_numeric_NAN = np.loadtxt(filename, delimiter = ';')\n",
    "leading_co_data_numeric_NAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7cfef941",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2000.,    40.,   365.,  3121.,  4241., 13621.],\n",
       "       [ 2000.,    40.,   365.,  3061.,  4171., 15041.],\n",
       "       [ 1000.,    40.,   365.,  2160.,  3280., 15340.],\n",
       "       ...,\n",
       "       [   nan,    40.,   365.,  4201.,  5001., 16600.],\n",
       "       [ 1000.,    40.,   365.,  2080.,  3320., 15600.],\n",
       "       [ 2000.,    40.,   365.,  4601.,  4601., 16600.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Como tiene valores nulos entonces usamos genfromtxt\n",
    "filename = \"C:/Users/m.pirela.escobar/OneDrive - Accenture/Documents/Courses/Data_Analyst/Data Analyst Course/S10 - Working with Text Files/L15/Lending-Company-Numeric-Data-NAN.csv\"\n",
    "leading_co_data_numeric_NAN = np.genfromtxt(filename, delimiter = ';')\n",
    "leading_co_data_numeric_NAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "30cdc5d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1000.,    40.,   365.,  2160.,  3280., 15340.],\n",
       "       [ 2000.,    40.,   365.,  3041.,  4241., 15321.],\n",
       "       [ 2000.,    50.,   365.,  3470.,  4820., 13720.],\n",
       "       ...,\n",
       "       [   nan,    40.,   365.,  4201.,  5001., 16600.],\n",
       "       [ 1000.,    40.,   365.,  2080.,  3320., 15600.],\n",
       "       [ 2000.,    40.,   365.,  4601.,  4601., 16600.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leading_co_data_numeric_NAN = np.genfromtxt(filename, delimiter = ';', skip_header = 2)\n",
    "leading_co_data_numeric_NAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cca799a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2000.,    40.,   365.,  3121.,  4241., 13621.],\n",
       "       [ 2000.,    40.,   365.,  3061.,  4171., 15041.],\n",
       "       [ 1000.,    40.,   365.,  2160.,  3280., 15340.],\n",
       "       ...,\n",
       "       [ 2000.,    40.,   365.,  3401.,    nan, 16600.],\n",
       "       [ 2000.,    40.,   365.,    nan,  5440., 16600.],\n",
       "       [   nan,    40.,   365.,  4201.,  5001., 16600.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leading_co_data_numeric_NAN = np.genfromtxt(filename, delimiter = ';', skip_footer = 2)\n",
    "leading_co_data_numeric_NAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "789c037d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[13621.,  2000.,    40.],\n",
       "       [15041.,  2000.,    40.],\n",
       "       [15340.,  1000.,    40.],\n",
       "       ...,\n",
       "       [16600.,    nan,    40.],\n",
       "       [15600.,  1000.,    40.],\n",
       "       [16600.,  2000.,    40.]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leading_co_data_numeric_NAN = np.genfromtxt(filename, delimiter = ';', usecols = (5,0,1))\n",
    "leading_co_data_numeric_NAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "71e66b30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[15340.,  1000.,    40.],\n",
       "       [15321.,  2000.,    40.],\n",
       "       [13720.,  2000.,    50.],\n",
       "       ...,\n",
       "       [16600.,  2000.,    40.],\n",
       "       [16600.,  2000.,    40.],\n",
       "       [16600.,    nan,    40.]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leading_co_data_numeric_NAN = np.genfromtxt(filename, delimiter = ';', usecols = (5,0,1),\n",
    "                                                                                   skip_header = 2, skip_footer = 2)\n",
    "leading_co_data_numeric_NAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7ba280b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15340. 15321. 13720. ... 16600. 16600. 16600.]\n",
      "[1000. 2000. 2000. ... 2000. 2000.   nan]\n",
      "[40. 40. 50. ... 40. 40. 40.]\n"
     ]
    }
   ],
   "source": [
    "# para seleccionar varias columnas a la vez y convertirlas individualmente se puede usar la forma de Python para Tuples\n",
    "leading_co_data_5, leading_co_data_0, leading_co_data_1, = np.genfromtxt(filename, delimiter = ';', usecols = (5,0,1), \n",
    "                                                                        skip_header = 2, skip_footer= 2, unpack = True)\n",
    "\n",
    "print(leading_co_data_5)\n",
    "print(leading_co_data_0)\n",
    "print(leading_co_data_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f39a85af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
